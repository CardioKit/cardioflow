{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e653e44-993b-43a7-b7c4-e11b7d7491d0",
   "metadata": {},
   "source": [
    "# Cross-Device Federated Unsupervised Learning of Electrocardiogram Signals\n",
    "\n",
    "This is the analysis script of the results of the federated learning and on-device fine-tuning (personalized) routines exported from the mobile devices to the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd476f-880b-4ece-aa41-6554afc9e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d435d-9e67-4b0b-8469-4ab3f187d490",
   "metadata": {},
   "source": [
    "## 1. Loading of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae8aad-5d3f-4577-bbe5-042ddcc8cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(path):\n",
    "    pd.set_option('future.no_silent_downcasting', True)\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for file in glob.glob(path + \"*.csv\"):\n",
    "        temp = pd.read_csv(file, header=None)\n",
    "        temp.columns = [\"segment\", \"quality\", \"groundtruth\", \"residual\", \"embedding\"]\n",
    "        temp[\"device\"] = int(file.rsplit('/', 1)[-1].replace(\"device_\", \"\").replace(\"_ecg_data.csv\", \"\"))\n",
    "\n",
    "        temp_ = temp['embedding'].str.split(';', expand=True)\n",
    "        col_names_embedding = [f'lvsd_{i+1}' for i in range(temp_.shape[1])]\n",
    "    \n",
    "        temp_.columns = col_names_embedding\n",
    "        temp_ = temp_.astype(float)\n",
    "    \n",
    "        temp = pd.concat([temp, temp_], axis=1)\n",
    "        temp = temp.drop('embedding', axis=1)\n",
    "        \n",
    "        group_means = temp.groupby('device')[col_names_embedding].transform('mean')\n",
    "        temp['euclidean_distance'] = np.sqrt(((temp[col_names_embedding] - group_means) ** 2).sum(axis=1))\n",
    "            \n",
    "        df = pd.concat([df, temp])\n",
    "\n",
    "    df.groundtruth = df.groundtruth.replace({\"Normal\": 0, \"PAC\": 1, \"PVC\": 2})\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56629c-366a-49ce-a947-765ce2bb1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(group):\n",
    "    return (group - group.mean()) / group.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1978bc19-e43e-4257-9bfe-00f397a8e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_federated = load_results(\"./results/federated/\")\n",
    "df_personalized = load_results(\"./results/personalized/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fb394-5557-4cf3-9f84-04b469e6f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_federated[\"residual_standardized\"] = df_federated.groupby('device')['residual'].transform(standardize)\n",
    "df_personalized[\"residual_standardized\"] = df_personalized.groupby('device')['residual'].transform(standardize)\n",
    "\n",
    "df_federated[\"euclidean_distance_standardized\"] = df_federated.groupby('device')['euclidean_distance'].transform(standardize)\n",
    "df_personalized[\"euclidean_distance_standardized\"] = df_personalized.groupby('device')['euclidean_distance'].transform(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ec833-0248-4e2a-8cec-2d790d1aa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_segments = pd.read_csv(\"./results/test_segments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c157153-c76e-4ef4-aab2-17e8bdcec958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_federated[\"test\"] = df_federated.segment.isin(test_segments.testSegment)\n",
    "df_personalized[\"test\"] = df_personalized.segment.isin(test_segments.testSegment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7901f13-f18e-4b32-ad5c-e95a73053b13",
   "metadata": {},
   "source": [
    "## 2. Data Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129abf0b-2a33-4ef1-a26b-16ec838d9d45",
   "metadata": {},
   "source": [
    "First, we want to check the residual per segment, which is directly related to the loss of the optimization process. Since we know that one segment was the test data set, there should be no segment that differs greatly from the others in terms of the residual/error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3708a-9c5e-473f-b061-ce522f2f8f58",
   "metadata": {},
   "source": [
    "### 2.1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf9836-c66a-4514-8919-049a28068806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_segments(df, path, mode=\"federated\"):\n",
    "    \n",
    "    df = df.sort_values(by=[\"device\"])\n",
    "    segment_loss = df.groupby([\"device\", \"segment\"])[\"residual\"].mean().reset_index()\n",
    "    segment_loss['segments'] = segment_loss.groupby(['device']).cumcount()\n",
    "    segment_loss.reset_index(drop=True, inplace=True)\n",
    "    segment_loss = segment_loss.merge(df[['device', 'segment', 'test']], on=['device', 'segment'])\n",
    "    \n",
    "    g = sns.FacetGrid(segment_loss, col=\"device\", col_wrap=4, height=4, aspect=2)\n",
    "    \n",
    "    def barplot_with_highlight(data, **kwargs):\n",
    "        sns.barplot(data=data, x=\"segments\", y=\"residual\", hue=\"test\", dodge=False, palette={True: 'orange', False: 'royalblue'}, legend=True, **kwargs)\n",
    "    \n",
    "    g.map_dataframe(barplot_with_highlight)\n",
    "    \n",
    "    handles = [plt.Line2D([0], [0], color='orange', lw=8, label='Train'),\n",
    "               plt.Line2D([0], [0], color='royalblue', lw=8, label='Test')]\n",
    "    plt.legend(handles=handles,title='Segment', loc='upper right', labels=['Test', 'Train'], fontsize=30, title_fontsize=30)\n",
    "    \n",
    "    g.set_titles(\"Device {col_name}\", size=30)\n",
    "    g.fig.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "    g.set_axis_labels(\"Segments\", \"Residual (MAE)\", fontsize=30)\n",
    "    g.set(xticks=[])\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        ticks = ax.get_yticks()\n",
    "        new_ticks = [0.0, 0.05, 0.1]\n",
    "        ax.set_yticks(new_ticks)\n",
    "        ax.set_yticklabels(new_ticks, fontsize=30)\n",
    "        \n",
    "    g.fig.suptitle(f\"Average Reconstruction Error (Mean Absolute Error) of the Segments for the {mode} Model\", fontsize=30, y=1.05)\n",
    "    \n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a581878-1e92-44ec-8e40-5d45f537882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_space(df, label=\"groundtruth\", method=\"pca\", path=\"./media/embedding.png\", fontsize=12, num_samples = 50000):\n",
    "    \n",
    "    col_names_embedding = [f'lvsd_{i+1}' for i in range(12)]\n",
    "    X = df[col_names_embedding].values\n",
    "    color = df[label]\n",
    "\n",
    "    row_indices = np.random.choice(X.shape[0], num_samples, replace=True)\n",
    "    X = X[row_indices, :]\n",
    "    if method == \"tsne\":\n",
    "        algo = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3)\n",
    "    else:\n",
    "        algo = PCA(n_components=2)\n",
    "\n",
    "    X_emb = algo.fit_transform(X)\n",
    "    X_emb = pd.DataFrame(X_emb, columns=[\"A1\", \"A2\"])\n",
    "    X_emb[\"label\"] = color.values[row_indices]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5)) #plt.figure(figsize=(5, 5))\n",
    "    palette = sns.color_palette(\"tab20\", len(df[label].unique()))\n",
    "    sns.scatterplot(data=X_emb, x=\"A1\", y=\"A2\", hue=\"label\", palette=palette, s=2, legend=False)\n",
    "\n",
    "    ax.set_xlabel(\"First Embedding Axis\", fontsize=fontsize)\n",
    "    ax.set_ylabel(\"Second Embedding Axis\", fontsize=fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "    \n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721133e-d8d9-4dc3-bda8-694a1e0acbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_distribution(df, path=\"./media/data_distribution.png\"):\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(15, 12), sharex=True, sharey=True)\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    fig.suptitle('Class Distribution of Heartbeat Segments by Device/Subject', fontsize=16)\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < len(df):\n",
    "            device_subject = df.loc[i, 'Device/Subject']\n",
    "            values = df.loc[i, ['Normal', 'PAC', 'PVC']]\n",
    "            bars = values.plot(kind='bar', ax=ax)\n",
    "    \n",
    "            # Add numbers on the bars\n",
    "            for bar in bars.patches:\n",
    "                height = bar.get_height()\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center',\n",
    "                    va='bottom'\n",
    "                )\n",
    "    \n",
    "            ax.set_title(device_subject)\n",
    "            ax.set_ylabel('Count')\n",
    "            ax.set_xticklabels(['Normal', 'PAC', 'PVC'], rotation=45)\n",
    "    \n",
    "    for j in range(len(df), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927be54e-a040-4ee2-b54e-31339f0759a6",
   "metadata": {},
   "source": [
    "### 2.2. Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a9967-735d-4dd1-a0d4-668aa6c5e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_segments(df_federated, \"./media/loss_segment_federated.png\", mode=\"Federated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cefb73-5489-4310-8955-2e85a8d1c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_segments(df_personalized, \"./media/loss_segment_personalized.png\", mode=\"Fine-tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf8a9d-8168-441b-99ca-9a7e22191a26",
   "metadata": {},
   "source": [
    "Distribution of annotations among the twenty devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa2f3f-0cde-4e88-884b-e08f7cc1afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_subject_mapping = pd.read_csv(\"./results/device_subject.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fd1ed-7d2b-4c72-8287-dc75035e4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_distribution = pd.pivot_table(\n",
    "    df_federated, values='quality', index=['device'], columns=['groundtruth'], aggfunc=\"count\",\n",
    ").rename({0: \"Normal\", 1: \"PAC\", 2: \"PVC\"}, axis=1).reset_index().merge(device_subject_mapping, on=\"device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0033ac3-d02e-4491-b91b-abe1147896fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_distribution[\"Device/Subject\"] = \"Device \" + df_class_distribution.device.astype(str) + \" / \" + df_class_distribution.subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6918b72-18cb-4679-b058-3106baf3faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_distribution(df_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c277334-6928-48f6-a8ed-1bd98d3785a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total ECG segments\", \"\\t Personalized:\", len(df_personalized), \"\\t Federated:\", len(df_federated))\n",
    "print(\"ECG segments normal\", \"\\t Personalized:\", len(df_personalized[df_personalized.groundtruth == 0]), \"\\t Federated:\", len(df_federated[df_federated.groundtruth == 0]))\n",
    "print(\"ECG segments anomal\", \"\\t Personalized:\", len(df_personalized[df_personalized.groundtruth > 0]), \"\\t Federated:\", len(df_federated[df_federated.groundtruth > 0]))\n",
    "print(\"ECG segments PAC\", \"\\t Personalized:\", len(df_personalized[df_personalized.groundtruth == 1]), \"\\t Federated:\", len(df_federated[df_federated.groundtruth == 1]))\n",
    "print(\"ECG segments PVC\", \"\\t Personalized:\", len(df_personalized[df_personalized.groundtruth == 2]), \"\\t Federated:\", len(df_federated[df_federated.groundtruth == 2]))\n",
    "print(\"ECGs medium quality\", \"\\t Personalized:\", len(df_personalized[df_personalized.quality == \"medium\"]), \"\\t Federated:\", len(df_federated[df_federated.quality == \"medium\"]))\n",
    "print(\"ECGs excellent quality\", \"\\t Personalized:\", len(df_personalized[df_personalized.quality == \"excellent\"]), \"\\t Federated:\", len(df_federated[df_federated.quality == \"excellent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6939c-7e85-4555-8cd6-76946a7d1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding_space(df_federated, label=\"device\", method=\"tsne\", fontsize=12, num_samples=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41821b80-64ac-4a87-8096-045e5cb9502f",
   "metadata": {},
   "source": [
    "## 3. Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2539d8-9a25-4c65-90e0-bbea3fbe0e65",
   "metadata": {},
   "source": [
    "### 3.1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874dabfc-99e4-48f2-b67f-3809159cde54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold(fpr, tpr, thresholds):\n",
    "    distances = np.sqrt((1 - tpr) ** 2 + fpr ** 2)\n",
    "    best_index = np.argmin(distances)\n",
    "    best_threshold = thresholds[best_index]\n",
    "    return best_threshold\n",
    "\n",
    "def plot_roc_curve_comparison(ax, df_federated, df_personalized, device=None, fontsize=12):\n",
    "    \n",
    "    if device is not None:\n",
    "        df_federated = df_federated.loc[df_federated.device == device,:]\n",
    "        df_personalized = df_personalized.loc[df_personalized.device == device,:]\n",
    "\n",
    "    y = df_federated.groundtruth > 0\n",
    "    \n",
    "    pred = df_federated.residual_standardized\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y, pred)\n",
    "    thres_fed_res = get_best_threshold(fpr, tpr, thresh)\n",
    "    auc = metrics.roc_auc_score(y, pred)\n",
    "    ax.plot(fpr, tpr, label=\"Fed Res (AUC=\" + str(np.round(auc, 2)) + \")\")\n",
    "\n",
    "    pred = df_federated.combined\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y, pred)\n",
    "    thres_fed_resemb = get_best_threshold(fpr, tpr, thresh)\n",
    "    auc = metrics.roc_auc_score(y, pred)\n",
    "    ax.plot(fpr, tpr, label=\"Fed ResEmb (AUC=\" + str(np.round(auc, 2)) + \")\")\n",
    "\n",
    "    pred = df_personalized.residual_standardized\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y, pred)\n",
    "    thres_ft_res = get_best_threshold(fpr, tpr, thresh)\n",
    "    auc = metrics.roc_auc_score(y, pred)\n",
    "    ax.plot(fpr, tpr, label=\"FT Res (AUC=\" + str(np.round(auc, 2)) + \")\")\n",
    "    \n",
    "    pred = df_personalized.combined\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y, pred)\n",
    "    thres_ft_resemb = get_best_threshold(fpr, tpr, thresh)\n",
    "    auc = metrics.roc_auc_score(y, pred)\n",
    "    ax.plot(fpr, tpr, label=\"FT ResEmb (AUC=\" + str(np.round(auc, 2)) + \")\")\n",
    "    \n",
    "    if device != None:\n",
    "        ax.set_title(f\"Device {str(device)}\", size=fontsize+4)\n",
    "    ax.legend(loc=0, fontsize=fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "    return thres_fed_res, thres_fed_resemb, thres_ft_res, thres_ft_resemb\n",
    "\n",
    "def create_roc_curve_grid(df_federated, df_personalized, rows, cols, fontsize=14, path=\"./media/roc_curve_comparison_grid.png\"):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows), sharex=True, sharey=True)\n",
    "    thresholds = []\n",
    "\n",
    "    for k in range(1, rows * cols + 1):\n",
    "        device = k\n",
    "        ax = axes[(k-1) // cols, (k-1) % cols]\n",
    "        _, _, _, t_ft_resemb = plot_roc_curve_comparison(ax, df_federated, df_personalized, device=device, fontsize=fontsize)\n",
    "        thresholds.append(t_ft_resemb)\n",
    "\n",
    "    fig.suptitle('Individual ROC AUC Comparison for Each Device', fontsize=fontsize + 4)\n",
    "    fig.text(0.5, -0.01, 'False Positive Rate', ha='center', fontsize=fontsize + 4)\n",
    "    fig.text(-0.01, 0.5, 'True Positive Rate', va='center', rotation='vertical', fontsize=fontsize + 4)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.985])\n",
    "    \n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    return thresholds\n",
    "\n",
    "def create_roc_curve_single(df_federated, df_personalized, fontsize=12, path=\"./media/roc_curve_comparison.png\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    t_fed_res, t_fed_resemb, t_ft_res, t_ft_resemb = plot_roc_curve_comparison(\n",
    "        ax,\n",
    "        df_federated,\n",
    "        df_personalized,\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=fontsize)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=fontsize)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return t_fed_res, t_fed_resemb, t_ft_res, t_ft_resemb\n",
    "\n",
    "def plot_confusion_matrix(ax, df, threshold, fontsize=14, path=\"./media/confusion_matrix.png\"):\n",
    "    \n",
    "    y_true = df.groundtruth > 0\n",
    "    y_pred = df.combined > threshold\n",
    "\n",
    "    bas = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    custom_labels = ['Normal', 'Anomaly']\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=custom_labels)\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues, colorbar=False)\n",
    "\n",
    "    return cm, bas\n",
    "\n",
    "def calculate_cm_metrics(cm):\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    \n",
    "    specificity = TN / (TN + FP)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    f1_score = (2*TP) / (2*TP + FP + FN)\n",
    "\n",
    "    scores = {\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"f1\": f1_score,\n",
    "    }\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def confusion_matrix_metrics(df, threshold):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    cm_single, bas_single = plot_confusion_matrix(axes, df, threshold)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./media/confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    metrics_cm = calculate_cm_metrics(cm_single)\n",
    "    print(\n",
    "        \"Overall\",\n",
    "        f\"Threshold: {np.round(threshold, 4)}\",\n",
    "        f\"Sensitivity {np.round(metrics_cm['sensitivity'], 4)}\\t\",\n",
    "        f\"Specificity {np.round(metrics_cm['specificity'], 4)}\\t\",\n",
    "        \"Balanced Accuracy:\", np.round(bas_single, 4),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97913122-f1a3-4ee6-9d9d-38a581644e7e",
   "metadata": {},
   "source": [
    "### 3.2. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0d020-c6a3-4d67-8965-77f8bf6f583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_federated[\"combined\"] = df_federated.euclidean_distance_standardized + df_federated.residual_standardized\n",
    "df_federated[\"combined\"] = df_federated.groupby('device')['combined'].transform(standardize)\n",
    "\n",
    "df_personalized[\"combined\"] = df_personalized.euclidean_distance_standardized + df_personalized.residual_standardized\n",
    "df_personalized[\"combined\"] = df_personalized.groupby('device')['combined'].transform(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd9c16-80c8-4026-b04b-9f74cf210acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_noisy_signal = False\n",
    "if filter_noisy_signal:\n",
    "    mask_federated = ~((df_federated.quality == \"medium\") & (df_federated.groundtruth == 0))\n",
    "    mask_personalized = ~((df_personalized.quality == \"medium\") & (df_personalized.groundtruth == 0))\n",
    "    df_federated = df_federated[mask_federated].reset_index(drop=True)\n",
    "    df_personalized = df_personalized[mask_personalized].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4e596-a209-4f47-921b-f6193aa1319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_fed_res, t_fed_resemb, t_ft_res, t_ft_resemb = create_roc_curve_single(df_federated, df_personalized, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b114e2-96f6-42a2-8e1b-18fe2b1a9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_all = create_roc_curve_grid(df_federated, df_personalized, rows=5, cols=4, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e3f76-f58b-45ce-a997-fee3f74dadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [t_fed_res, t_fed_resemb]:\n",
    "    confusion_matrix_metrics(df_federated, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0060427-562a-4160-9fbe-52346b3c7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [t_ft_res, t_ft_resemb]:\n",
    "    confusion_matrix_metrics(df_personalized, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e559e-4364-4365-9aad-0d86be207a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAC\n",
    "confusion_matrix_metrics(df_personalized[df_personalized.groundtruth != 2], t_ft_resemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220bf580-37ff-4e6f-869a-cf579f8a114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PVC\n",
    "confusion_matrix_metrics(df_personalized[df_personalized.groundtruth != 1], t_ft_resemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2e052-aa85-43a4-a851-899f8de7c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fp_mQuality = (\n",
    "    (df_personalized.groundtruth > 0) != (df_personalized.combined > t_ft_resemb)\n",
    ") & (\n",
    "    df_personalized.groundtruth == 0\n",
    ") & (\n",
    "    df_personalized.quality == \"medium\"\n",
    ")\n",
    "print(\"Number of FP with a medium signal quality:\", len(df_personalized[mask_fp_mQuality]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b5d31-eef4-450c-bdc9-7adbe909da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 5\n",
    "cols = 4\n",
    "cms = []\n",
    "bas_all = []\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for k in range(1, rows * cols + 1):\n",
    "    ax = axes[k-1]\n",
    "    cm, bas = plot_confusion_matrix(\n",
    "        ax,\n",
    "        df_personalized[df_personalized.device == k],\n",
    "        thresholds_all[k-1]\n",
    "    )\n",
    "    ax.set_title(f\"Device {str(k)}\", size=12+4)\n",
    "    cms.append(cm)\n",
    "    bas_all.append(bas)\n",
    "\n",
    "fig.suptitle('Individual Confusion Matrix for Each Device', fontsize=12 + 4)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.985])\n",
    "plt.savefig(\"./media/confusion_matrix_all.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c3f44-873a-4d85-92c0-6db353f38abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_all = np.zeros((2,2))\n",
    "for i, k in enumerate(cms):\n",
    "    metrics_cm = calculate_cm_metrics(k)\n",
    "    print(\n",
    "        f\"Device {i+1}\\t\",\n",
    "        f\"Subject {device_subject_mapping[device_subject_mapping.device == i+1]['subject'].iloc[0]}\\t\",\n",
    "        f\"Threshold {np.round(thresholds_all[i], 4)}\\t\",\n",
    "        f\"Sensitivity {np.round(metrics_cm['sensitivity'], 4)}\\t\",\n",
    "        f\"Specificity {np.round(metrics_cm['specificity'], 4)}\\t\",\n",
    "        f\"Balanced Accuracy {np.round(bas_all[i], 4)}\",\n",
    "    )\n",
    "    cm_all += k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783784b-3fb4-49ce-90a8-4df9d15ce776",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529c1c9-b53d-460d-9ae3-5d963457601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_cm_metrics(cm_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ce243-3d2f-4eba-b06f-e750d97a05c0",
   "metadata": {},
   "source": [
    "## 4. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f27162-da01-4fef-8561-db76c27f4d65",
   "metadata": {},
   "source": [
    "### 4.1. Federated Model\n",
    "\n",
    "Loading the weights from the federated learning process to either make predictions on ECG data or to sample ECGs from the latent vector space (though no variational autoencoders). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1cb00-0694-4cd8-bf6e-35407df24b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from io import BytesIO\n",
    "from autoencoder import AE\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b7d7ce-013e-43e1-908c-68db7e23492d",
   "metadata": {},
   "source": [
    "Load weights and transform them into a numpy array to inject them into the shared autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7498c4-f439-47a4-a099-2b58be070310",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weights = \"../src/federated/weights/round-250-weights.npz\"\n",
    "data = np.load(path_weights, allow_pickle=True)\n",
    "parameters_serialized = data['arr_0'].item()\n",
    "pretrained_weights = [np.load(BytesIO(tensor), allow_pickle=False) for tensor in parameters_serialized.tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89541fc-d471-4642-ba0e-90ecae792082",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE()\n",
    "with torch.no_grad():\n",
    "    for k, name in enumerate(model.named_parameters()):\n",
    "        if k % 2 == 0:\n",
    "            param = name[1]\n",
    "            param.copy_(torch.from_numpy(pretrained_weights[int(k/2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51010a29-ea2f-4b97-8ebf-bf8c73dde44a",
   "metadata": {},
   "source": [
    "The reconstructed samples of the autoencoder optimized by the federated learning routine tend to be noisy. Therefore, we introduce a simple smoothing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e038a3b-5d95-49d1-a763-c58b130dc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(signal, window_size):\n",
    "    window = np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(signal, window, 'same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acce104-f43a-49a6-a0a9-72452f02452b",
   "metadata": {},
   "source": [
    "Systematically toggling the values in the latent vector space is used to analyze the change in the reconstruction and thus possibly give the dimensions an interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111dbfbf-0480-476f-9ace-7639f9218017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(val, dim):\n",
    "    # a randomly chosen encoding from the df_personalized dataframe\n",
    "    embedding = [0.97, -1.57, 3.55, 3.67, -1.82, 3.61, -0.53, -2.51, 4.461, 2.12, 4.73, -0.74]\n",
    "    my_tensor = torch.tensor(embedding, dtype=torch.float32)\n",
    "    my_tensor[dim] = val\n",
    "    reconstruction = moving_average(model.decoder(my_tensor).detach().numpy(), 10)\n",
    "    plt.plot(reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3b07c-ac9b-417c-8fa9-0419864f414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "floatSlider = widgets.FloatSlider(min=-10, max=10, step=0.1, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c223bb1-2d2f-4096-af09-611ab8cd622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(f, val=floatSlider, dim=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75af674-2a2a-4cf9-9710-73b6c1693b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = [0.97, -1.57, 3.55, 3.67, -1.82, 3.61, -0.53, -2.51, 4.461, 2.12, 4.73, -0.74]\n",
    "my_tensor = torch.tensor(embedding, dtype=torch.float32)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 15), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for k in range(12):\n",
    "    ax = axes[k]\n",
    "    my_tensor = torch.tensor(embedding, dtype=torch.float32)\n",
    "    for j in np.linspace(-5, 5, 5):\n",
    "        my_tensor[k] = j\n",
    "        # apply a smoothin operation to gain denoised signals\n",
    "        reconstruction = moving_average(model.decoder(my_tensor).detach().numpy(), 10)\n",
    "        ax.plot(reconstruction)\n",
    "    ax.set_title(f'Dimension={k+1}')\n",
    "\n",
    "fig.suptitle('Reconstruction Plots for Toggling the Value of Each Latent Vector Space Dimension', fontsize=16)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "\n",
    "plt.savefig(\"./media/reconstructions.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b38b3a8-526e-40a8-b594-5c43edfafb35",
   "metadata": {},
   "source": [
    "### 4.2. Sample Data Plot\n",
    "\n",
    "To include a visual data example in the respective article, a suitable example is loaded from the Icentia11k dataset and the three relevant label classes (normal, PAC, PVC) and the corresponding ECGs are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e7f23-86f3-4c27-ab6b-bf160209d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sample needs to be downloaded manually\n",
    "df_plot = pd.read_csv(\"./sample/p03984_24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5727e034-7fd2-4e62-ab23-29b9efc27e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pac = df_plot[df_plot.annotation == \"pac\"].index\n",
    "index_pvc = df_plot[df_plot.annotation == \"pvc\"].index\n",
    "index_normal = df_plot[df_plot.annotation == \"normal\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de4f43-2f14-4b55-b2ce-b2ed2da8edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_pac = df_plot.iloc[(index_pac[2]-125):(index_pac[2]+125), 0].reset_index(drop=True).reset_index()\n",
    "values_pvc = df_plot.iloc[(index_pvc[2]-125):(index_pvc[2]+125), 0].reset_index(drop=True).reset_index()\n",
    "values_normal = df_plot.iloc[(index_normal[2]-125):(index_normal[2]+125), 0].reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693ccea-ddb7-499a-ad2f-a69fda993f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_pac[\"annotation\"] = \"PAC\"\n",
    "values_pvc[\"annotation\"] = \"PVC\"\n",
    "values_normal[\"annotation\"] = \"Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce6dee-9e73-4143-9687-a76f902bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.concat([values_pac, values_pvc, values_normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4538bc6-1b6d-48b3-8742-5a453dc39ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_texts = {\n",
    "    'PAC': 'PAC',\n",
    "    'PVC': 'PVC',\n",
    "    'Normal': 'Normal'\n",
    "}\n",
    "\n",
    "palette = sns.color_palette(\"husl\", len(values['annotation'].unique()))\n",
    "g = sns.FacetGrid(values, row=\"annotation\", aspect=5, height=2, despine=False)\n",
    "g.map_dataframe(sns.lineplot, x=\"index\", y=\"signal\", hue=\"annotation\", palette=palette)\n",
    "\n",
    "for ax, annotation in zip(g.axes.flatten(), custom_texts.keys()):\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "    ax.tick_params(left=False, bottom=False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_title('')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    x_position = 135\n",
    "    y_position = values[values['annotation'] == annotation]['signal'].mean() + 0.2\n",
    "    ax.text(x_position, y_position, custom_texts[annotation], verticalalignment='center', fontsize=14)\n",
    "    \n",
    "g.fig.subplots_adjust(hspace=0)\n",
    "\n",
    "g.savefig('./media/data.png', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21351b3e-4283-4803-80af-2bb0b101c07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c01332-5b91-48f5-bdb5-378463d1ddd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
